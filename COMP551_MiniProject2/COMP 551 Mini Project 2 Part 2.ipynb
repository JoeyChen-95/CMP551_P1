{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP551 Mini Project_Part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7FhGP0fXm4J"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRVi9j2VzrPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412b450b-7472-4c76-e517-c994d3233717"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1qyaldGmQZ9O8pLxdN3kPc_e9JxQUXl33\n",
        "!gdown https://drive.google.com/uc?id=1OD_IiluXFASNz-1d7XrvbjjLMJPSK3Nl\n",
        "!gdown https://drive.google.com/uc?id=1rmuVA-xVCrnQYGQOAA_pw958QMt11Vu5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qyaldGmQZ9O8pLxdN3kPc_e9JxQUXl33\n",
            "To: /content/fake_news_val.csv\n",
            "100% 6.53M/6.53M [00:00<00:00, 53.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OD_IiluXFASNz-1d7XrvbjjLMJPSK3Nl\n",
            "To: /content/fake_news_train.csv\n",
            "100% 63.8M/63.8M [00:00<00:00, 113MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rmuVA-xVCrnQYGQOAA_pw958QMt11Vu5\n",
            "To: /content/fake_news_test.csv\n",
            "100% 9.48M/9.48M [00:00<00:00, 82.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cuOlDUZ53NZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n41n5mLA5aSn"
      },
      "source": [
        "y_train = []\n",
        "x_train = []\n",
        "with open(\"fake_news_train.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, quoting=csv.QUOTE_ALL) # change contents to floats\n",
        "    for row in reader: # each row is a list\n",
        "        x_train.append(row[0])\n",
        "        y_train.append(row[1])\n",
        "\n",
        "y_train=y_train[1::]\n",
        "x_train=x_train[1::]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAWvRrcZQ9wA"
      },
      "source": [
        "y_test = []\n",
        "x_test = []\n",
        "with open(\"fake_news_test.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, quoting=csv.QUOTE_ALL) # change contents to floats\n",
        "    for row in reader: # each row is a list\n",
        "        x_test.append(row[0])\n",
        "        y_test.append(row[1])\n",
        "\n",
        "y_test=y_test[1::]\n",
        "x_test=x_test[1::]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqMMHthGrpGE"
      },
      "source": [
        "y_val = []\n",
        "x_val = []\n",
        "with open(\"fake_news_val.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, quoting=csv.QUOTE_ALL) # change contents to floats\n",
        "    for row in reader: # each row is a list\n",
        "        x_val.append(row[0])\n",
        "        y_val.append(row[1])\n",
        "\n",
        "x_val=x_val[1::]\n",
        "y_val=y_val[1::]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fa8z5FOpXEV"
      },
      "source": [
        "# Building a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWmsb8kzpaNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65386ed3-67ab-4877-caed-84df58a787f4"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "text_clf = Pipeline(memory=None,\n",
        "         steps=[('vect',\n",
        "                 CountVectorizer(analyzer='word', binary=True,\n",
        "                                 decode_error='strict',\n",
        "                                 encoding='utf-8',\n",
        "                                 input='content', lowercase=False, max_df=1.0,\n",
        "                                 max_features=None, min_df=1,\n",
        "                                 ngram_range=(1, 2), preprocessor=None,\n",
        "                                 stop_words=None, strip_accents=None,\n",
        "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "                                 tokenizer=None)),\n",
        "                ('tfidf',\n",
        "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
        "                                  sublinear_tf=False, use_idf=True)),\n",
        "                ('clf',\n",
        "                 LogisticRegression(C=80, class_weight='balanced', dual=False,\n",
        "                                    fit_intercept=True, intercept_scaling=1,\n",
        "                                    l1_ratio=None, max_iter=1000,\n",
        "                                    multi_class='multinomial', n_jobs=None,\n",
        "                                    penalty='l2', random_state=None,\n",
        "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                                    warm_start=False))],\n",
        "         verbose=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text_clf.fit(x_train,y_train)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=True,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=False, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 2), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=Non...\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=80, class_weight='balanced', dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=1000,\n",
              "                                    multi_class='multinomial', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPBMgCavqc8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55803d96-f151-4ab6-e95c-f9d655b122dd"
      },
      "source": [
        "predicted=text_clf.predict(x_val)\n",
        "print('validation accuracy')\n",
        "print(np.mean(predicted==y_val))\n",
        "predicted=text_clf.predict(x_test)\n",
        "print('test accuracy')\n",
        "print(np.mean(predicted==y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation accuracy\n",
            "0.7945\n",
            "test accuracy\n",
            "0.801\n"
          ]
        }
      ]
    }
  ]
}