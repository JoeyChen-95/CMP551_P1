{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP 551 Mini Project 3 Submission",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnB5hP0CSxcY"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvFcfkS1C1sX"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1O3AMQz_CmapznZFoFDOVghTlC_uvJRNq #Download kaggle.json\n",
        "!pip install kaggle #Install kaggle api\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/\" #Configure the path of kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz2HEjzcCKnH"
      },
      "source": [
        "!kaggle competitions download -c comp-551-fall-2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8RN-TM_FEYD"
      },
      "source": [
        "!unzip images_l.pkl.zip\n",
        "!unzip images_test.pkl.zip\n",
        "!unzip images_ul.pkl.zip\n",
        "!unzip labels_l.pkl.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O75Ql8OUF_C8"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "with open(\"labels_l.pkl\", 'rb') as f: data = pickle.load(f)\n",
        "labels_train_raw = np.array(data)\n",
        "labels_train_raw = labels_train_raw.astype(np.double)\n",
        "with open(\"images_l.pkl\", 'rb') as f: data = pickle.load(f)\n",
        "images_train_raw = np.array(data)\n",
        "images_train_raw = images_train_raw.astype(np.double)\n",
        "with open(\"images_ul.pkl\", 'rb') as f: data = pickle.load(f)\n",
        "images_unlabel = np.array(data)\n",
        "with open(\"images_test.pkl\", 'rb') as f: data = pickle.load(f)\n",
        "images_test = np.array(data)\n",
        "print('label for training:')\n",
        "print(labels_train_raw.shape)\n",
        "print('images for training:')\n",
        "print(images_train_raw.shape)\n",
        "print('unlabel images:')\n",
        "print(images_unlabel.shape)\n",
        "print('images for testing:')\n",
        "print(images_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0pPvJ6DHhAr"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE8jh2p581MR"
      },
      "source": [
        "images_train = images_train_raw.copy()\n",
        "labels_digits_train = labels_train_raw[:, :10]\n",
        "labels_letters_train = labels_train_raw[:, 10:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if8ODpdHCUJn"
      },
      "source": [
        "## Without Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZRjZlp8CWRr"
      },
      "source": [
        "x_train = images_train[:29000,:,:].reshape(-1, 56, 56, 1)\n",
        "y_train_digits = labels_digits_train[:29000,:]\n",
        "y_train_letters = labels_letters_train[:29000,:]\n",
        "x_val = images_train[29000:,:,:].reshape(-1, 56, 56, 1)\n",
        "y_val_digits = labels_digits_train[29000:,:]\n",
        "y_val_letters = labels_letters_train[29000:,:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewln2vOgCfrt"
      },
      "source": [
        "## With Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-VO1guFF3gG"
      },
      "source": [
        "from numpy.random import seed\n",
        "from numpy.random import rand\n",
        "from scipy.ndimage import rotate\n",
        "import cv2\n",
        "def rotation_aug_rand(threshold):\n",
        "  image_size = images_train.shape[1:]\n",
        "  training_size = images_train.shape[0]\n",
        "  augmented = []\n",
        "  for i in range(0,training_size):\n",
        "    original = images_train[i]\n",
        "    augmented.append(original)\n",
        "    angle1 = np.random.choice([np.random.default_rng().uniform(low=-threshold, high=-threshold+15),np.random.default_rng().uniform(low=threshold-15, high=threshold)])\n",
        "    rotated_img1 = rotate(original, angle=angle1, reshape=False)\n",
        "    angle2 = np.random.choice([np.random.default_rng().uniform(low=-threshold, high=-threshold+15),np.random.default_rng().uniform(low=threshold-15, high=threshold)])\n",
        "    rotated_img2 = rotate(original, angle=angle2, reshape=False)\n",
        "    augmented.append(rotated_img1)\n",
        "    augmented.append(rotated_img2)\n",
        "  augmented = np.stack(augmented,axis = 0)\n",
        "  return augmented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3g_ECPF7V9"
      },
      "source": [
        "augmented_train = rotation_aug_rand(36)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q__j1Sz6M6Ik"
      },
      "source": [
        "augmented_digits_labels = np.repeat(labels_digits_train,3,axis=0)\n",
        "augmented_letters_labels = np.repeat(labels_letters_train,3,axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn_zp2NUDbXV"
      },
      "source": [
        "x_train = augmented_train[:80000,:,:].reshape(-1, 56, 56, 1)\n",
        "y_train_digits = augmented_digits_labels[:80000,:]\n",
        "y_train_letters = augmented_letters_labels[:80000,:]\n",
        "x_val = augmented_train[80000:,:,:].reshape(-1, 56, 56, 1)\n",
        "y_val_digits = augmented_digits_labels[80000:,:]\n",
        "y_val_letters = augmented_letters_labels[80000:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QLR0d75TXnI"
      },
      "source": [
        "## Noise Reduction (Optional)\n",
        "**Warning: This method may decrease performance in some cases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlOlsYPQYvX7"
      },
      "source": [
        "def noiseReduction(images_set):\n",
        "  for imageIndex in range(0, images_set.shape[0]-1):\n",
        "    if imageIndex % 1000 == 0:\n",
        "      print(imageIndex)\n",
        "    w,h = 56,56\n",
        "    black_point = 0\n",
        "    for x in range(0,w-1):\n",
        "        for y in range(0,h-1):\n",
        "            mid_pixel = images_set[imageIndex][x][y] #Find pixel value of the mid point\n",
        "            # Sharpen\n",
        "            if(mid_pixel>30):\n",
        "              images_set[imageIndex][x][y]=255\n",
        "            else:\n",
        "              images_set[imageIndex][x][y]=0\n",
        "            if mid_pixel > 100: # Find pixel of up, botton, left, right\n",
        "                top_pixel = images_set[imageIndex][x][y-1]\n",
        "                left_pixel = images_set[imageIndex][x-1][y]\n",
        "                down_pixel = images_set[imageIndex][x][y+1]\n",
        "                right_pixel = images_set[imageIndex][x+1][y]\n",
        "    \n",
        "                #Number of  black point around\n",
        "                if top_pixel == 0:\n",
        "                    black_point += 1\n",
        "                if left_pixel == 0:\n",
        "                    black_point += 1\n",
        "                if down_pixel == 0:\n",
        "                    black_point += 1\n",
        "                if right_pixel == 0:\n",
        "                    black_point += 1\n",
        "                if black_point >= 3:\n",
        "                    images_set[imageIndex][x][y]=0\n",
        "            black_point = 0\n",
        "  return images_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ7EXqa7r44L"
      },
      "source": [
        "def noiseReduction(images_set):\n",
        "  for i in range(0, images_set.shape[0]):\n",
        "    images_set[i, images_set[i] < 0.25] = 0\n",
        "  return images_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cRdeuxecIAI"
      },
      "source": [
        "def minMaxNormalization(images_set):\n",
        "  for i in range(0, images_set.shape[0]):\n",
        "    images_set[i] = (images_set[i] - np.min(images_set[i])) / (np.max(images_set[i]) - np.min(images_set[i]))\n",
        "  return images_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znfFNMsrTPSk"
      },
      "source": [
        "# Building CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJTojslx7pQN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, Activation, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(56, 56, 1))\n",
        "\n",
        "joint = Conv2D(64, (5, 5), padding = \"same\")(inputs)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = Conv2D(64, (5, 5), padding = \"same\")(joint)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = MaxPool2D((2, 2), (2, 2))(joint)\n",
        "joint = Dropout(0.3)(joint)\n",
        "\n",
        "joint = Conv2D(128, (5, 5), padding = \"same\")(joint)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = Conv2D(128, (5, 5), padding = \"same\")(joint)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = MaxPool2D((2, 2), (2, 2))(joint)\n",
        "joint = Dropout(0.3)(joint)\n",
        "\n",
        "joint = Conv2D(256, (5, 5), padding = \"same\")(joint)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = Conv2D(256, (5, 5), padding = \"same\")(joint)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = MaxPool2D((2, 2), (2, 2))(joint)\n",
        "joint = Dropout(0.3)(joint)\n",
        "\n",
        "joint = Flatten()(joint)\n",
        "joint = Dense(512)(joint)\n",
        "joint = Activation(\"relu\")(joint)\n",
        "joint = BatchNormalization()(joint)\n",
        "joint = Dropout(0.3)(joint)\n",
        "\n",
        "digits_branch = Dense(256)(joint)\n",
        "digits_branch = Activation(\"relu\")(digits_branch)\n",
        "digits_branch = BatchNormalization()(digits_branch)\n",
        "digits_branch = Dropout(0.3)(digits_branch)\n",
        "digits_branch = Dense(10, activation = \"softmax\", name = \"digits_output\")(digits_branch)\n",
        "\n",
        "letters_branch = Dense(256)(joint)\n",
        "letters_branch = Activation(\"relu\")(letters_branch)\n",
        "letters_branch = BatchNormalization()(letters_branch)\n",
        "letters_branch = Dropout(0.3)(letters_branch)\n",
        "letters_branch = Dense(26, activation = \"softmax\", name = \"letters_output\")(letters_branch)\n",
        "\n",
        "model = Model(inputs = inputs, outputs = [digits_branch, letters_branch])\n",
        "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMuD_qS0D1Nb"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD0RsZNDl6z9"
      },
      "source": [
        "class CombinedValidation(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    accuracy = get_combined_validation_accuracy(self.model)\n",
        "    combined_val_accuracies.append(accuracy)\n",
        "    print(\" - combined validation accuracy: \" + str(accuracy))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y-bPWZvNJrz"
      },
      "source": [
        "#import pickle\n",
        "#model = pickle.load(open('model 98.4 98.6.pkl', 'rb'))\n",
        "\n",
        "def get_combined_validation_accuracy(model):\n",
        "  predictions = model.predict(x_val.reshape(-1, 56, 56, 1))\n",
        "  predictions_indices_digits = np.argmax(predictions[0], axis = 1)\n",
        "  predictions_indices_letters = np.argmax(predictions[1], axis = 1)\n",
        "  validation_indices_digits = np.argmax(y_val_digits, axis = 1)\n",
        "  validation_indices_letters = np.argmax(y_val_letters, axis = 1)\n",
        "  correct = 0\n",
        "  total = predictions_indices_digits.shape[0]\n",
        "  for i in range(total):\n",
        "    if predictions_indices_digits[i] == validation_indices_digits[i] and predictions_indices_letters[i] == validation_indices_letters[i]:\n",
        "      correct = correct + 1\n",
        "  return correct / total\n",
        "\n",
        "#print(get_combined_validation_accuracy(model))\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5GCrQBEdOl7"
      },
      "source": [
        "rlrop_digits = ReduceLROnPlateau(monitor = \"val_digits_output_accuracy\", factor = 0.5, patience = 2, verbose = 1)\n",
        "rlrop_letters = ReduceLROnPlateau(monitor = \"val_letters_output_accuracy\", factor = 0.5, patience = 2, verbose = 1)\n",
        "combined_validation = CombinedValidation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8r6oC1mH1Wp"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khd3ygbX0c35"
      },
      "source": [
        "combined_val_accuracies = []\n",
        "model.fit(x = x_train, y = {\"digits_output\": y_train_digits, \"letters_output\": y_train_letters}, \n",
        "          batch_size = 128, epochs = 30, callbacks = [rlrop_digits, rlrop_letters, combined_validation],\n",
        "          validation_data = (x_val, {\"digits_output\": y_val_digits, \"letters_output\": y_val_letters}),\n",
        "          shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyyDaxqVDiBZ"
      },
      "source": [
        "## With Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ97TEaeWYey"
      },
      "source": [
        "#model aggregating without replacement\n",
        "\n",
        "digits_list = []\n",
        "letters_list = []\n",
        "for i in range (0,6):\n",
        "  x_train = images_train[5000 * i:5000 * (i+1),:,:].reshape(-1, 56, 56, 1)\n",
        "  y_train_digits = labels_digits_train[5000 * i:5000 * (i+1),:]\n",
        "  y_train_letters = labels_letters_train[5000 * i:5000 * (i+1),:]\n",
        "  x_val = images_train[5000 * (5-i):5000 * (6-i),:,:].reshape(-1, 56, 56, 1)\n",
        "  y_val = labels_digits_train[5000 * (5-i):5000 * (6-i),:]\n",
        "  y_val_digits = labels_digits_train[5000 * (5-i):5000 * (6-i),:]\n",
        "  y_val_letters = labels_letters_train[5000 * (5-i):5000 * (6-i),:]\n",
        "  model.fit(x = x_train, y = {\"digits_output\": y_train_digits, \"letters_output\": y_train_letters}, \n",
        "            batch_size = 128, epochs = 30, callbacks = [rlrop_digits, rlrop_letters], \n",
        "            validation_data = (x_val, {\"digits_output\": y_val_digits, \"letters_output\": y_val_letters}),\n",
        "            shuffle = True)\n",
        "  predictions = model.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "  indices_digits = np.argmax(predictions[0], axis = 1)\n",
        "  indices_letters = np.argmax(predictions[1], axis = 1)\n",
        "  digits_list.append(indices_digits)\n",
        "  letters_list.append(indices_letters)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdcaN6IM1ZT1"
      },
      "source": [
        "#aggregate the results of non-replacement\n",
        "from scipy import stats\n",
        "digits_predict = np.array(digits_list)\n",
        "letters_predict = np.array(letters_list)\n",
        "\n",
        "aggregated_digits = stats.mode(digits_predict,axis = 0)[0]\n",
        "aggregated_letters = stats.mode(letters_predict,axis = 0)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2BnRyl-HRqP"
      },
      "source": [
        "#model aggregating with replacement\n",
        "\n",
        "digits_list = []\n",
        "letters_list = []\n",
        "xy_train_digits =  \n",
        "for i in range (0,10):\n",
        "  x_train = images_train[5000 * i:5000 * (i+1),:,:].reshape(-1, 56, 56, 1)\n",
        "  y_train_digits = labels_digits_train[5000 * i:5000 * (i+1),:]\n",
        "  y_train_letters = labels_letters_train[5000 * i:5000 * (i+1),:]\n",
        "  x_val = images_train[5000 * (5-i):5000 * (6-i),:,:].reshape(-1, 56, 56, 1)\n",
        "  y_val = labels_digits_train[5000 * (5-i):5000 * (6-i),:]\n",
        "  y_val_digits = labels_digits_train[5000 * (5-i):5000 * (6-i),:]\n",
        "  y_val_letters = labels_letters_train[5000 * (5-i):5000 * (6-i),:]\n",
        "  model.fit(x = x_train, y = {\"digits_output\": y_train_digits, \"letters_output\": y_train_letters},\n",
        "            batch_size = 128, epochs = 30, callbacks = [rlrop_digits, rlrop_letters], \n",
        "            validation_data = (x_val, {\"digits_output\": y_val_digits, \"letters_output\": y_val_letters}),\n",
        "            shuffle = True)\n",
        "  predictions = model.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "  indices_digits = np.argmax(predictions[0], axis = 1)\n",
        "  indices_letters = np.argmax(predictions[1], axis = 1)\n",
        "  digits_list.append(indices_digits)\n",
        "  letters_list.append(indices_letters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJObgWvyS2Uf"
      },
      "source": [
        "indices_digits = np.squeeze(aggregated_digits)\n",
        "indices_letters = np.squeeze(aggregated_letters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYUhxbCaDm19"
      },
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8EM8OjDvOgd",
        "outputId": "3c7bd045-e836-4448-a4ac-1a795c39cd31"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(model, open(\"model adam 98.2 97.9 96.9.pkl\", \"wb\"))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://aceb4c23-0265-49e7-bd55-37ff0f9affff/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGb3IOWmEFjb"
      },
      "source": [
        "# Utilizing Unlabelled Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WPnDFBISdH"
      },
      "source": [
        "model = pickle.load(open(\"model adam 98.0 98.0 96.8.pkl\", \"rb\"))\n",
        "predictions_unlabelled = model.predict(images_unlabel.reshape(-1, 56, 56, 1))\n",
        "x_train_with_unlabelled = np.concatenate((x_train, images_unlabel.reshape(-1, 56, 56, 1)), axis = 0)\n",
        "y_train_digits_with_unlabelled = np.concatenate((y_train_digits, predictions_unlabelled[0]), axis = 0)\n",
        "y_train_letters_with_unlabelled = np.concatenate((y_train_letters, predictions_unlabelled[1]), axis = 0)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UxBsEHaPahH"
      },
      "source": [
        "combined_val_accuracies = []\n",
        "model.fit(x = x_train_with_unlabelled, y = {\"digits_output\": y_train_digits_with_unlabelled, \"letters_output\": y_train_letters_with_unlabelled},\n",
        "          batch_size = 128, epochs = 30, callbacks = [rlrop_digits, rlrop_letters, combined_validation],\n",
        "          validation_data = (x_val, {\"digits_output\": y_val_digits, \"letters_output\": y_val_letters}),\n",
        "          shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F6emokhD5Za"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB02zWR97DFD"
      },
      "source": [
        "import csv\n",
        "predictions = model.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "indices_digits = np.argmax(predictions[0], axis = 1)\n",
        "indices_letters = np.argmax(predictions[1], axis = 1)\n",
        "with open(\"predictions.csv\", \"w\", newline=\"\") as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=\",\")\n",
        "  writer.writerow([\"# Id\", \"Category\"])\n",
        "  for i in range(0, indices_digits.shape[0]):\n",
        "    writer.writerow([i, \n",
        "                     ('0' * indices_digits[i]) + '1' + ('0' * (9 - indices_digits[i]))\n",
        "                     + ('0' * indices_letters[i]) + '1' + ('0' * (25 - indices_letters[i]))\n",
        "                     ])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYwebjnHyG39"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udaz97UyIUb"
      },
      "source": [
        "import pickle\n",
        "import csv\n",
        "import numpy as np\n",
        "model1 = pickle.load(open(\"model adam 98.2 97.9 96.9.pkl\", \"rb\"))\n",
        "model2 = pickle.load(open(\"model adam 98.0 98.0 96.8.pkl\", \"rb\"))\n",
        "# model3 = pickle.load(open(\"model_91.9.pkl\", \"rb\"))\n",
        "# model4 = pickle.load(open(\"model_93.6.pkl\", \"rb\"))\n",
        "model5 = pickle.load(open(\"model 98.4 98.6.pkl\", \"rb\"))\n",
        "prediction1=model1.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "prediction2=model2.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "# prediction3=model3.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "# prediction4=model4.predict(images_test.reshape(-1, 56, 56, 1))\n",
        "prediction5=model5.predict(images_test.reshape(-1, 56, 56, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUjbYL_LyNBj"
      },
      "source": [
        "prediction11=np.array(prediction1[0])\n",
        "prediction21=np.array(prediction2[0])\n",
        "# prediction31=np.array(prediction3[0])\n",
        "# prediction41=np.array(prediction4[0])\n",
        "prediction51=np.array(prediction5[0])\n",
        "predictions1=(prediction11+prediction51)/2\n",
        "prediction12=np.array(prediction1[1])\n",
        "prediction22=np.array(prediction2[1])\n",
        "# prediction32=np.array(prediction3[1])\n",
        "# prediction42=np.array(prediction4[1])\n",
        "prediction52=np.array(prediction5[1])\n",
        "predictions2=(prediction12+prediction52)/2\n",
        "indices_digits = np.argmax(predictions1,axis=1)\n",
        "indices_letters = np.argmax(predictions2,axis=1)\n",
        "with open('predictions1127_4.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "  writer.writerow(['# Id', 'Category'])\n",
        "  for i in range(0, 15000):\n",
        "    writer.writerow([i, \n",
        "                     ('0' * indices_digits[i]) + '1'  + ('0' * (9 - indices_digits[i]))\n",
        "                     + ('0' * indices_letters[i]) + '1' + ('0' * (25 - indices_letters[i]))\n",
        "                     ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-l71Hrnc4_H"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS1dKlJKC2iw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "combined_val_accuracies_2 = combined_val_accuracies.copy()\n",
        "print(combined_val_accuracies_2)\n",
        "plt.rcParams[\"figure.figsize\"] = (4,2)\n",
        "plt.plot(range(1, 31), combined_val_accuracies_1)\n",
        "plt.plot(range(1, 31), combined_val_accuracies_2)\n",
        "plt.legend([\"Without unlabelled data\", \"With unlabelled data fed back\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}